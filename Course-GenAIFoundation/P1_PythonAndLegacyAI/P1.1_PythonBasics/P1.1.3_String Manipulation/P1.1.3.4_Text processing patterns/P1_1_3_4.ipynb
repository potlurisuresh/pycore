{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eb8f045",
   "metadata": {},
   "source": [
    "# üìò P1.1.3.4 ‚Äì String Manipulation\n",
    "## Topic: Text Processing Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8014da90",
   "metadata": {},
   "source": [
    "## üéØ Learning Objectives\n",
    "By the end of this notebook, you will:\n",
    "- Clean and normalize text consistently\n",
    "- Tokenize text using simple patterns\n",
    "- Remove noise (punctuation, stopwords, extra spaces)\n",
    "- Apply basic text preprocessing steps used in AI\n",
    "- Build small reusable text-cleaning functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca266b2",
   "metadata": {},
   "source": [
    "## üßº Pattern 1: Normalize Case\n",
    "Convert text to lowercase to make comparisons consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711c90a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Python is GREAT!\"\n",
    "print(text.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35d845e",
   "metadata": {},
   "source": [
    "## ‚úÇÔ∏è Pattern 2: Trim Extra Whitespace\n",
    "Remove leading/trailing spaces and collapse extra spaces inside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165c5db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = \"   AI   is   powerful   \"\n",
    "clean = \n",
    ".join(raw.split())\n",
    "print(clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ccc2bc",
   "metadata": {},
   "source": [
    "## üßπ Pattern 3: Remove Punctuation (Simple)\n",
    "Keep only letters and spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cb2c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "text = \"Hello, world!!!\"\n",
    "clean = text.translate(str.maketrans('', '', string.punctuation))\n",
    "print(clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5388ba86",
   "metadata": {},
   "source": [
    "## ü™ì Pattern 4: Tokenization (Simple)\n",
    "Split text into words using spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413cb19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"AI models learn from data\"\n",
    "tokens = sentence.split()\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dae8a36",
   "metadata": {},
   "source": [
    "## üß± Pattern 5: Remove Stopwords (Intermediate)\n",
    "Stopwords are common words with low meaning (e.g., the, is, and)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d182141c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [\"this\", \"is\", \"a\", \"simple\", \"test\"]\n",
    "stopwords = {\"is\", \"a\", \"the\", \"and\"}\n",
    "filtered = [t for t in tokens if t not in stopwords]\n",
    "print(filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182af6b6",
   "metadata": {},
   "source": [
    "## üß© Pattern 6: Replace Variants\n",
    "Normalize variants into one form (e.g., 'AI', 'A.I.')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eac0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"AI and A.I. are the same here\"\n",
    "normalized = text.replace(\"A.I.\", \"AI\")\n",
    "print(normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761572b5",
   "metadata": {},
   "source": [
    "## üîÅ Pattern 7: Clean Pipeline (Intermediate)\n",
    "Combine steps into one reusable function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45700018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "sample = \"  AI,   is AMAZING!!!  \"\n",
    "print(clean_text(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2361647f",
   "metadata": {},
   "source": [
    "## ü§ñ AI Use Case (Brief)\n",
    "- Clean raw text before NLP models\n",
    "- Normalize casing and punctuation\n",
    "- Reduce noise to improve model accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b738625",
   "metadata": {},
   "source": [
    "### ‚úÖ Key Takeaways\n",
    "- Text processing uses repeatable patterns\n",
    "- Normalize case, whitespace, and punctuation\n",
    "- Tokenize and filter noise\n",
    "- Combine steps into reusable functions\n",
    "- Essential for NLP and AI pipelines"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
